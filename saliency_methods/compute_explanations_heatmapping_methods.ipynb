{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing heatmaps for saliency methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('image', cmap='Purples')\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.backend.tensorflow_backend import set_session, clear_session\n",
    "\n",
    "from scripts.analyzers import run_interpretation_methods\n",
    "from scripts.models import create_model_llr, train_model\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import warnings\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = '../results/saliency_methods'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/data_vary_signal_exact_2021-04-27-21-29-44_pattern_type_5.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_saved_data(data_path):\n",
    "    with open(data_path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['0.00_0.50_0.50', '0.02_0.49_0.49', '0.04_0.48_0.48', '0.06_0.47_0.47', '0.08_0.46_0.46']\n",
    "# keys = ['0.00_0.50_0.50', '0.04_0.48_0.48', '0.08_0.46_0.46', '0.12_0.44_0.44', '0.16_0.42_0.42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_params = [('gradient', {}), ('deep_taylor', {}), ('lrp.z', {}), ('lrp.alpha_beta', {'alpha' : 2, 'beta' : 1}), ('pattern.net', {}), ('pattern.attribution', {}), ('input_t_gradient', {})]\n",
    "methods = [method[0] for method in methods_params]\n",
    "print(methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = {'input_dim' : 64, 'output_dim' : 2, 'regularizer' : None, 'epochs' : 200, 'runs' : 100, 'save_data' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_saved_data(data_path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_empty_results_dict():\n",
    "    return {'results': dict(),\n",
    "        'method_names': list()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_results(output_dir : str, results: dict, suffix: str) -> None: \n",
    "    output_path = os.path.join(output_dir, f'results_{suffix}.pkl')\n",
    "    print(f'Output path: {output_path}')\n",
    "    with open(output_path, 'wb') as f: \n",
    "        pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 100 runs for all five parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = generate_empty_results_dict()\n",
    "results['method_names'] = methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc_dict = dict()\n",
    "for weights, data_list in data.items():\n",
    "    print(f'Weight: {weights}')\n",
    "    \n",
    "    results_per_weight = list()\n",
    "    acc_per_weight = list()\n",
    "    val_acc_per_weight = list()\n",
    "    \n",
    "    for data_run in data_list:\n",
    "        clear_session()\n",
    "        \n",
    "        output = dict()\n",
    "        data_train = data_run['train']\n",
    "        data_val = data_run['val']\n",
    "        \n",
    "        X_train = data_train['x']\n",
    "        y_train_bin = data_train['y']\n",
    "        y_train = np_utils.to_categorical(y_train_bin, num_classes = 2)\n",
    "        \n",
    "        X_val = data_val['x']\n",
    "        y_val_bin = data_val['y']\n",
    "        y_val = np_utils.to_categorical(y_val_bin, num_classes = 2)\n",
    "\n",
    "        model = create_model_llr(output_dim = params['output_dim'], activation = 'softmax', regularizer = params['regularizer'], input_dim = params['input_dim'])\n",
    "        model_trained, acc, val_acc = train_model(model, X_train, y_train, X_val, y_val, epochs = params['epochs'], verbose = False)\n",
    "        model_weights = model_trained.get_weights()\n",
    "        \n",
    "        heatmaps = run_interpretation_methods(model_trained, methods = methods_params, data = X_val, X_train_blob = X_train, normalize = False)\n",
    "        \n",
    "        output['model'] = model_weights # TODO write function to load model + weights \n",
    "        output['explanations'] = heatmaps\n",
    "        \n",
    "        results_per_weight += [output]\n",
    "        acc_per_weight += [acc[-1]]\n",
    "        val_acc_per_weight += [val_acc[-1]]\n",
    "        \n",
    "    results['results'][weights] = results_per_weight\n",
    "    acc_dict[weights] = {'acc' : acc_per_weight, 'val_acc' : val_acc_per_weight}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(acc_dict['0.00_0.50_0.50']['acc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    print(f'Final accuracy for {key}: {np.mean(acc_dict[key][\"val_acc\"]):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pattern_type(data_path: str) -> str:\n",
    "    return data_path.split('.')[2].split('pattern_type_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if params['save_data']:\n",
    "    pattern_type = f'pattern_type_{extract_pattern_type(data_path=file_path)}'\n",
    "    dump_results(output_dir = result_dir, results = results, suffix = f'heatmapping_methods_{pattern_type}')\n",
    "    dump_results(output_dir = result_dir, results = acc_dict, suffix = f'accuracies_{pattern_type}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}